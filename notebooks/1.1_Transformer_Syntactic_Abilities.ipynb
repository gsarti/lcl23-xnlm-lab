{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gsarti/lcl23-xnlm-lab/blob/main/notebooks/1.1_Transformer_Syntactic_Abilities.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assessing Transformer Model Syntactic Abilities**\n",
    "\n",
    "In this notebook, we will see how to assess the syntactic abilities of a Transformer model trained with Masked Language Modeling (MLM) objective function. In particular, we will test the abilities of the model on the *subject-verb agreement* phenomena.\n",
    "\n",
    "The notebook is adapted from the experiments made by Yoav Goldberg in \"*Assessing BERT's Syntactic Abilities*\" (https://arxiv.org/pdf/1901.05287.pdf).\n",
    "For further details, please also see the original github repo by Yoav Goldberg: https://github.com/yoavg/bert-syntax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Masked Language Modeling**\n",
    "\n",
    "BERT is trained to approximate the Masked Language Modeling function, i.e. predict the identity of masked words in an input sequence (e.g. sentence).\n",
    "\n",
    "<div>\n",
    "  <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200422002516/maskedLanguage.jpg\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "*(Source: https://www.geeksforgeeks.org/understanding-bert-nlp/)*\n",
    "\n",
    "Relying on the MLM training function, wee can test the performance of the model in learning subject-verb agreement patterns.\n",
    "From Goldberg's paper: \n",
    "\n",
    "> *‚Äúfeeding into BERT the complete sentence, while masking out the single focus verb. I then ask BERT for its word predictions for the masked position, and compare the score assigned to the original correct verb to the score assigned to the incorrect one.‚Äù*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Installation and imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/alessio/.local/lib/python3.10/site-packages (4.29.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: filelock in /home/alessio/.local/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alessio/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: fsspec in /home/alessio/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Dataset**\n",
    "\n",
    "Below is reported how to load and format the dataset so that it can then be passed directly to the Transformer model. \n",
    "\n",
    "In this notebook, we will be utilizing the dataset defined in \"Targeted Syntactic Evaluation of Language Models\" (Marvin and Linzen, 2018, link to the paper: https://aclanthology.org/D18-1151.pdf). \n",
    "The dataset consists of various stimuli designed to assess the language model's proficiency in the following syntactic phenomena:\n",
    "\n",
    "\n",
    "*   Subject-Verb Agreement;\n",
    "*   Reflexive Anaphora;\n",
    "*   Negative Polarity Items.\n",
    "\n",
    "The dataset can be download from https://github.com/yoavg/bert-syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Drive folder\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Data Investigation**\n",
    "\n",
    "Before proceeding with the data processing, let's examine the structure of the dataset more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obj_rel_across_anim</td>\n",
       "      <td>sing_MS_MV_sing_ES_EV</td>\n",
       "      <td>the author that the guard likes laughs</td>\n",
       "      <td>the author that the guard likes laugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>obj_rel_across_anim</td>\n",
       "      <td>sing_MS_MV_sing_ES_EV</td>\n",
       "      <td>the author that the guard likes swims</td>\n",
       "      <td>the author that the guard likes swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obj_rel_across_anim</td>\n",
       "      <td>sing_MS_MV_sing_ES_EV</td>\n",
       "      <td>the author that the guard likes smiles</td>\n",
       "      <td>the author that the guard likes smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obj_rel_across_anim</td>\n",
       "      <td>sing_MS_MV_sing_ES_EV</td>\n",
       "      <td>the author that the guard likes is tall</td>\n",
       "      <td>the author that the guard likes are tall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obj_rel_across_anim</td>\n",
       "      <td>sing_MS_MV_sing_ES_EV</td>\n",
       "      <td>the author that the guard likes is old</td>\n",
       "      <td>the author that the guard likes are old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                      1  \\\n",
       "0  obj_rel_across_anim  sing_MS_MV_sing_ES_EV   \n",
       "1  obj_rel_across_anim  sing_MS_MV_sing_ES_EV   \n",
       "2  obj_rel_across_anim  sing_MS_MV_sing_ES_EV   \n",
       "3  obj_rel_across_anim  sing_MS_MV_sing_ES_EV   \n",
       "4  obj_rel_across_anim  sing_MS_MV_sing_ES_EV   \n",
       "\n",
       "                                         2  \\\n",
       "0   the author that the guard likes laughs   \n",
       "1    the author that the guard likes swims   \n",
       "2   the author that the guard likes smiles   \n",
       "3  the author that the guard likes is tall   \n",
       "4   the author that the guard likes is old   \n",
       "\n",
       "                                          3  \n",
       "0     the author that the guard likes laugh  \n",
       "1      the author that the guard likes swim  \n",
       "2     the author that the guard likes smile  \n",
       "3  the author that the guard likes are tall  \n",
       "4   the author that the guard likes are old  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = \"../data/marvin_linzen_dataset.tsv\"\n",
    "\n",
    "df = pd.read_csv(test_dataset, delimiter='\\t', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['obj_rel_across_anim', 'obj_rel_within_anim',\n",
       "       'obj_rel_across_inanim', 'obj_rel_within_inanim', 'subj_rel',\n",
       "       'prep_anim', 'prep_inanim', 'obj_rel_no_comp_across_anim',\n",
       "       'obj_rel_no_comp_within_anim', 'obj_rel_no_comp_across_inanim',\n",
       "       'obj_rel_no_comp_within_inanim', 'simple_agrmt', 'sent_comp',\n",
       "       'vp_coord', 'long_vp_coord', 'reflexives_across',\n",
       "       'simple_reflexives', 'reflexive_sent_comp', 'npi_across_anim',\n",
       "       'npi_across_inanim', 'simple_npi_anim', 'simple_npi_inanim'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the different typologies of phenomena present in the dataset\n",
    "df[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118160</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author laughs</td>\n",
       "      <td>the author laugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118161</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author swims</td>\n",
       "      <td>the author swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118162</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author smiles</td>\n",
       "      <td>the author smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118163</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author is tall</td>\n",
       "      <td>the author are tall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118164</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author is old</td>\n",
       "      <td>the author are old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1                   2                    3\n",
       "118160  simple_agrmt  sing_MS_MV   the author laughs     the author laugh\n",
       "118161  simple_agrmt  sing_MS_MV    the author swims      the author swim\n",
       "118162  simple_agrmt  sing_MS_MV   the author smiles     the author smile\n",
       "118163  simple_agrmt  sing_MS_MV  the author is tall  the author are tall\n",
       "118164  simple_agrmt  sing_MS_MV   the author is old   the author are old"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Samples from the dataset with simple subject-verb agreement\n",
    "df[df[0] == 'simple_agrmt'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120820</th>\n",
       "      <td>long_vp_coord</td>\n",
       "      <td>sing_MS_LMV_LMV</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120821</th>\n",
       "      <td>long_vp_coord</td>\n",
       "      <td>sing_MS_LMV_LMV</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120822</th>\n",
       "      <td>long_vp_coord</td>\n",
       "      <td>sing_MS_LMV_LMV</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120823</th>\n",
       "      <td>long_vp_coord</td>\n",
       "      <td>sing_MS_LMV_LMV</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "      <td>the author knows many different foreign langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120824</th>\n",
       "      <td>long_vp_coord</td>\n",
       "      <td>sing_MS_LMV_LMV</td>\n",
       "      <td>the author likes to watch television shows and...</td>\n",
       "      <td>the author likes to watch television shows and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                1  \\\n",
       "120820  long_vp_coord  sing_MS_LMV_LMV   \n",
       "120821  long_vp_coord  sing_MS_LMV_LMV   \n",
       "120822  long_vp_coord  sing_MS_LMV_LMV   \n",
       "120823  long_vp_coord  sing_MS_LMV_LMV   \n",
       "120824  long_vp_coord  sing_MS_LMV_LMV   \n",
       "\n",
       "                                                        2  \\\n",
       "120820  the author knows many different foreign langua...   \n",
       "120821  the author knows many different foreign langua...   \n",
       "120822  the author knows many different foreign langua...   \n",
       "120823  the author knows many different foreign langua...   \n",
       "120824  the author likes to watch television shows and...   \n",
       "\n",
       "                                                        3  \n",
       "120820  the author knows many different foreign langua...  \n",
       "120821  the author knows many different foreign langua...  \n",
       "120822  the author knows many different foreign langua...  \n",
       "120823  the author knows many different foreign langua...  \n",
       "120824  the author likes to watch television shows and...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Samples from the dataset with subject-verb agreement with Long VP (verb phrase) coordination\n",
    "df[df[0] == 'long_vp_coord'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code are adapted from the script *eval_bert.py* available here: https://github.com/yoavg/bert-syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = []\n",
    "\n",
    "cc = Counter()\n",
    "for line in open(test_dataset, 'r'):\n",
    "  sample = line.strip().split(\"\\t\")\n",
    "\n",
    "  # Select only the configuration with simple subject-verb agreement\n",
    "  if sample[0] == \"simple_agrmt\":\n",
    "    cc[sample[1]]+=1\n",
    "\n",
    "    # Select the correct ('g') and the erroneous sentence ('ug)\n",
    "    g, ug = sample[-2], sample[-1]\n",
    "    g = g.split()\n",
    "    ug = ug.split()\n",
    "    assert(len(g)==len(ug)),(g,ug)\n",
    "\n",
    "    # Identify the difference between the two sentences (i.e. the different token)\n",
    "    diffs = [i for i,pair in enumerate(zip(g,ug)) if pair[0]!=pair[1]]\n",
    "    if (len(diffs)!=1):\n",
    "      continue    \n",
    "    assert(len(diffs)==1),diffs\n",
    "\n",
    "    # Save in 'gv' and 'ugv' the correct and incorrect token\n",
    "    gv=g[diffs[0]]   # correct\n",
    "    ugv=ug[diffs[0]] # incorrect\n",
    "\n",
    "    # Recreate the input sequence by replace the target token with [MASK]\n",
    "    g[diffs[0]]=\"[MASK]\"\n",
    "    g.append(\".\")\n",
    "\n",
    "    # Filter the sentences that contains 'swims' as possible target token, since 'swims' does not exist in the model vocabulary\n",
    "    if gv != 'swims' and ugv != 'swims':\n",
    "      processed_dataset.append((sample[0],sample[1],\" \".join(g),gv,ugv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the data preparation process, each instance will have the following structure:\n",
    "\n",
    "*   Phenomena;\n",
    "*   Construction Template;\n",
    "*   Sentence with the masked target token;\n",
    "*   Target token with correct agreement;\n",
    "*    Target token with incorrect agreement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 120\n",
      "\n",
      "Input sample: ('simple_agrmt', 'sing_MS_MV', 'the author [MASK] tall .', 'is', 'are')\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(processed_dataset))\n",
    "print()\n",
    "\n",
    "print(\"Input sample:\", processed_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Loading the Pipeline**\n",
    "\n",
    "To carry out the experiments, we rely on the Huggingface's Transformers Library. \n",
    "\n",
    "Transformers ü§ó (https://huggingface.co/docs/transformers/index) ‚Äú*provides APIs and tools to easily download and train state-of-the-art pretrained models.*‚Äù\n",
    "\n",
    "For our specific scenario, we utilize the *pipeline* object (https://huggingface.co/docs/transformers/main_classes/pipelines), which offers a simple API dedicated to several tasks (e.g. Named Entity Recognition, Masked Language Modeling, Feature Extraction, and more).\n",
    "\n",
    "The *pipeline()* object can be instantiated as follows:\n",
    "\n",
    "```python\n",
    "nlp = pipeline(<task_name>, model=<model_name>)\n",
    "```\n",
    "\n",
    "In this notebook, we use *bert-base-cased* as Transformer model (12 layers, 12 attention heads, 768 hidden units). However, it is possible to use any other model that has been trained with the MLM function. The full list of available models can be found at the following link: [Huggingface Models](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\", model=\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Running the pipeline on the dataset**\n",
    "\n",
    "After loading the dataset and the model, we can simple call the *pipeline* on one item (i.e. sentence) as follows:\n",
    "\n",
    "```python\n",
    "predictions = nlp(<sentence>, targets=<target_tokens>)\n",
    "```\n",
    "\n",
    "\n",
    "The *targets* parameters allows us to provide the model with a set of target tokens in order to compute their probability for the MLM task.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the pilot [MASK] young .\n",
      "Targets: ('is', 'are')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.15975096821784973,\n",
       "  'token': 1110,\n",
       "  'token_str': 'is',\n",
       "  'sequence': 'the pilot is young.'},\n",
       " {'score': 8.954993245424703e-05,\n",
       "  'token': 1132,\n",
       "  'token_str': 'are',\n",
       "  'sequence': 'the pilot are young.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We select a sample sentence (and the corresponding target tokens) from our dataset\n",
    "sentence = processed_dataset[10][2]\n",
    "targets = processed_dataset[10][3:]\n",
    "\n",
    "# Sample sentence and target tokens\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Targets:\", targets)\n",
    "print()\n",
    "\n",
    "predictions = nlp(sentence, targets=targets)\n",
    "\n",
    "# Model MLM predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we apply our pipeline to all the sentences in the dataset and then we store the results in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"phenomena\", \"template\", \"sentence\", \n",
    "           \"correct_token\", \"prob_correct_token\", \n",
    "           \"incorrect_token\", \"prob_incorrect_token\"]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for input_sample in processed_dataset:\n",
    "  sentence = input_sample[2]\n",
    "  targets = input_sample[3:]\n",
    "\n",
    "  dict_results = {\"phenomena\": [input_sample[0]],\n",
    "                  \"template\": [input_sample[1]],\n",
    "                  \"sentence\": [sentence],\n",
    "                  \"correct_token\": [targets[0]],\n",
    "                  \"incorrect_token\": [targets[1]]}\n",
    "  \n",
    "  # Get BERT predictions and store in the  dictionary\n",
    "  predictions = nlp(sentence, targets=targets)\n",
    "  for pred in predictions:\n",
    "    token = pred[\"token_str\"]\n",
    "    prob = pred[\"score\"]\n",
    "    if token == targets[0]:\n",
    "      dict_results[\"prob_correct_token\"] = [prob]\n",
    "    else:\n",
    "      dict_results[\"prob_incorrect_token\"] = [prob]\n",
    "\n",
    "  df = pd.concat([df, pd.DataFrame(dict_results)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 10 rows of the resulting Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenomena</th>\n",
       "      <th>template</th>\n",
       "      <th>sentence</th>\n",
       "      <th>correct_token</th>\n",
       "      <th>prob_correct_token</th>\n",
       "      <th>incorrect_token</th>\n",
       "      <th>prob_incorrect_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] .</td>\n",
       "      <td>laughs</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>laugh</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] .</td>\n",
       "      <td>smiles</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] tall .</td>\n",
       "      <td>is</td>\n",
       "      <td>0.130696</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] old .</td>\n",
       "      <td>is</td>\n",
       "      <td>0.423882</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] young .</td>\n",
       "      <td>is</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phenomena    template                   sentence correct_token  \\\n",
       "0  simple_agrmt  sing_MS_MV        the author [MASK] .        laughs   \n",
       "0  simple_agrmt  sing_MS_MV        the author [MASK] .        smiles   \n",
       "0  simple_agrmt  sing_MS_MV   the author [MASK] tall .            is   \n",
       "0  simple_agrmt  sing_MS_MV    the author [MASK] old .            is   \n",
       "0  simple_agrmt  sing_MS_MV  the author [MASK] young .            is   \n",
       "\n",
       "   prob_correct_token incorrect_token  prob_incorrect_token  \n",
       "0            0.005252           laugh              0.000046  \n",
       "0            0.002515           smile              0.000057  \n",
       "0            0.130696             are              0.000045  \n",
       "0            0.423882             are              0.000553  \n",
       "0            0.098579             are              0.000016  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Evaluation**\n",
    "\n",
    "As a final step, we compute the performance of the model. Specifically, we calculate its accuracy, i.e. we verify how many times BERT was able to assign a higher probability to the target word with the correct subject-verb agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of correct predictions: 120\n",
      "Total number of wrong predictions: 0\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "corr = df.query('prob_correct_token > prob_incorrect_token')\n",
    "miss = df.query('prob_correct_token < prob_incorrect_token')\n",
    "\n",
    "tot_corr = len(corr)\n",
    "tot_miss = len(miss)\n",
    "\n",
    "print(\"Total number of correct predictions:\", tot_corr)\n",
    "print(\"Total number of wrong predictions:\", tot_miss)\n",
    "print()\n",
    "\n",
    "accuracy = tot_corr/(tot_corr+tot_miss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenomena</th>\n",
       "      <th>template</th>\n",
       "      <th>sentence</th>\n",
       "      <th>correct_token</th>\n",
       "      <th>prob_correct_token</th>\n",
       "      <th>incorrect_token</th>\n",
       "      <th>prob_incorrect_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] .</td>\n",
       "      <td>laughs</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>laugh</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] .</td>\n",
       "      <td>smiles</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] tall .</td>\n",
       "      <td>is</td>\n",
       "      <td>0.130696</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] old .</td>\n",
       "      <td>is</td>\n",
       "      <td>0.423882</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>sing_MS_MV</td>\n",
       "      <td>the author [MASK] young .</td>\n",
       "      <td>is</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>are</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>plur_MS_MV</td>\n",
       "      <td>the consultants [MASK] .</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>smiles</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>plur_MS_MV</td>\n",
       "      <td>the consultants [MASK] tall .</td>\n",
       "      <td>are</td>\n",
       "      <td>0.029917</td>\n",
       "      <td>is</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>plur_MS_MV</td>\n",
       "      <td>the consultants [MASK] old .</td>\n",
       "      <td>are</td>\n",
       "      <td>0.048789</td>\n",
       "      <td>is</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>plur_MS_MV</td>\n",
       "      <td>the consultants [MASK] young .</td>\n",
       "      <td>are</td>\n",
       "      <td>0.149911</td>\n",
       "      <td>is</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple_agrmt</td>\n",
       "      <td>plur_MS_MV</td>\n",
       "      <td>the consultants [MASK] short .</td>\n",
       "      <td>are</td>\n",
       "      <td>0.023601</td>\n",
       "      <td>is</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       phenomena    template                        sentence correct_token  \\\n",
       "0   simple_agrmt  sing_MS_MV             the author [MASK] .        laughs   \n",
       "0   simple_agrmt  sing_MS_MV             the author [MASK] .        smiles   \n",
       "0   simple_agrmt  sing_MS_MV        the author [MASK] tall .            is   \n",
       "0   simple_agrmt  sing_MS_MV         the author [MASK] old .            is   \n",
       "0   simple_agrmt  sing_MS_MV       the author [MASK] young .            is   \n",
       "..           ...         ...                             ...           ...   \n",
       "0   simple_agrmt  plur_MS_MV        the consultants [MASK] .         smile   \n",
       "0   simple_agrmt  plur_MS_MV   the consultants [MASK] tall .           are   \n",
       "0   simple_agrmt  plur_MS_MV    the consultants [MASK] old .           are   \n",
       "0   simple_agrmt  plur_MS_MV  the consultants [MASK] young .           are   \n",
       "0   simple_agrmt  plur_MS_MV  the consultants [MASK] short .           are   \n",
       "\n",
       "    prob_correct_token incorrect_token  prob_incorrect_token  \n",
       "0             0.005252           laugh              0.000046  \n",
       "0             0.002515           smile              0.000057  \n",
       "0             0.130696             are              0.000045  \n",
       "0             0.423882             are              0.000553  \n",
       "0             0.098579             are              0.000016  \n",
       "..                 ...             ...                   ...  \n",
       "0             0.001336          smiles              0.000065  \n",
       "0             0.029917              is              0.000175  \n",
       "0             0.048789              is              0.000271  \n",
       "0             0.149911              is              0.000322  \n",
       "0             0.023601              is              0.000388  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct predictions\n",
    "corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenomena</th>\n",
       "      <th>template</th>\n",
       "      <th>sentence</th>\n",
       "      <th>correct_token</th>\n",
       "      <th>prob_correct_token</th>\n",
       "      <th>incorrect_token</th>\n",
       "      <th>prob_incorrect_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [phenomena, template, sentence, correct_token, prob_correct_token, incorrect_token, prob_incorrect_token]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrect predictions\n",
    "miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Causal Language Modeling**\n",
    "\n",
    "While BERT is trained with the MLM function, Causal Lanugage Models are generally trained with the language modeling (LM) function, i.e. predicting the next token in an input sequence according to its previous context.\n",
    "\n",
    "<div>\n",
    "  <img src=\"https://lena-voita.github.io/resources/lectures/lang_models/neural/nn_lm_idea_linear-min.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "(Source: https://lena-voita.github.io/nlp_course/language_modeling.html)\n",
    "\n",
    "It is possible to reproduce the experiments just shown also with a Causal Language Model (e.g. GPT), whit a few adjustments.\n",
    "\n",
    "Given an input sequence, we can provide the model with the sequence up to the target token (i.e. prompt), and then ask to predict the next token and compare the probabilities associated with the two target words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading the model**\n",
    "\n",
    "To extract the probabilities from the target tokens, we can simply run the model on our input sequence.\n",
    "Before doing so, we need to load both the model and its tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running the model**\n",
    "\n",
    "By calling the *'model.generate()'* object on the input sequence: \n",
    "\n",
    "```python\n",
    "model.generate(input_ids)\n",
    "```\n",
    "\n",
    "it will be possible to return a generated sequence starting from the prompt defined with *'input_ids'*. It is also possible to specific several parameters to condition the generation of the model.\n",
    "\n",
    "At the end of the generation process, with:\n",
    "\n",
    "```python\n",
    "model.compute_transition_scores()\n",
    "```\n",
    " \n",
    "we can extract extract the probability scores at each generation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the author [MASK] .\n",
      "\n",
      "|   286 |  of      | -1.434 | 23.8339081407%\n",
      "|   262 |  the     | -1.334 | 26.3485491276%\n",
      "|  1492 |  book    | -2.173 | 11.3818027079%\n",
      "|   366 |  \"       | -2.134 | 11.8385106325%\n",
      "|   464 | The      | -1.662 | 18.9790815115%\n"
     ]
    }
   ],
   "source": [
    "sentence = processed_dataset[0][2]\n",
    "targets = processed_dataset[0][3:]\n",
    "\n",
    "print(\"Sentence:\", sentence)\n",
    "print()\n",
    "\n",
    "# Split the sentence to get the sequence up to the [MASK] token\n",
    "pre = sentence.split(\" [MASK] \")[0]\n",
    "inputs = tokenizer(pre, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=5, num_beams=4, return_dict_in_generate=True, output_scores=True)\n",
    "\n",
    "transition_scores = model.compute_transition_beam_scores(\n",
    "    outputs.sequences, outputs.scores, outputs.beam_indices)\n",
    "\n",
    "# input_length is the length of the input prompt for decoder-only models, like the GPT family, and 1 for\n",
    "# encoder-decoder models, like BART or T5.\n",
    "input_length = 1 if model.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
    "generated_tokens = outputs.sequences[:, input_length:]\n",
    "\n",
    "for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "    # | token | token string | logits | probability\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.10%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to condition the generation only on certain target tokens (i.e. the target verbs for the subject-verb agreement task), we can modify the previous code snipped by adjusting some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the author [MASK] .\n",
      "Targets: ('laughs', 'laugh')\n",
      "\n",
      "| 28124 | laughs   | -18.429 | 0.0000009915%\n",
      "\n",
      "| 44944 | laugh    | -19.947 | 0.0000002173%\n"
     ]
    }
   ],
   "source": [
    "sentence = processed_dataset[0][2]\n",
    "targets = processed_dataset[0][3:]\n",
    "\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Targets:\", targets)\n",
    "print()\n",
    "\n",
    "# Function to restrict the generated tokens of the model to the target ones\n",
    "def restrict_decode_vocab(batch_idx, prefix_beam):\n",
    "    restricted_vocab = tokenizer([targets], return_tensors=\"pt\")['input_ids'].tolist()\n",
    "  \n",
    "    return restricted_vocab\n",
    "\n",
    "# Split the sentence to get the sequence up to the [MASK] token\n",
    "pre = sentence.split(\" [MASK] \")[0]\n",
    "inputs = tokenizer(pre, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=1, num_return_sequences=2, return_dict_in_generate=True, \n",
    "                         output_scores=True, num_beams=4, prefix_allowed_tokens_fn=restrict_decode_vocab)\n",
    "\n",
    "transition_scores = model.compute_transition_beam_scores(\n",
    "    outputs.sequences, outputs.scores, outputs.beam_indices\n",
    ")\n",
    "\n",
    "# input_length is the length of the input prompt for decoder-only models, like the GPT family, and 1 for\n",
    "# encoder-decoder models, like BART or T5.\n",
    "input_length = 1 if model.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
    "generated_tokens = outputs.sequences[:, input_length:]\n",
    "\n",
    "# Probabilities for the first generation (i.e. with target_tokens = targets[0])\n",
    "for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "    # | token | token string | logits | probability\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.10%}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Probabilities for the second generation (i.e. with target_tokens = targets[1])\n",
    "for tok, score in zip(generated_tokens[1], transition_scores[1]):\n",
    "    # | token | token string | logits | probability\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.10%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
